{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>AF</th>\n",
       "      <th>AR</th>\n",
       "      <th>AS</th>\n",
       "      <th>AST</th>\n",
       "      <th>AY</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Date</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HC</th>\n",
       "      <th>HF</th>\n",
       "      <th>HR</th>\n",
       "      <th>HS</th>\n",
       "      <th>HST</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HY</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>league</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>07/08/09</td>\n",
       "      <td>H</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>bundesliga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FC Koln</td>\n",
       "      <td>08/08/09</td>\n",
       "      <td>H</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>bundesliga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hannover</td>\n",
       "      <td>08/08/09</td>\n",
       "      <td>H</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hertha</td>\n",
       "      <td>bundesliga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>08/08/09</td>\n",
       "      <td>D</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hoffenheim</td>\n",
       "      <td>bundesliga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>08/08/09</td>\n",
       "      <td>D</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mainz</td>\n",
       "      <td>bundesliga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AC    AF   AR    AS  AST   AY       AwayTeam      Date FTR    HC    HF  \\\n",
       "0   3.0  12.0  0.0  14.0  4.0  0.0      Stuttgart  07/08/09   H   6.0  12.0   \n",
       "1   1.0  10.0  0.0   7.0  0.0  1.0        FC Koln  08/08/09   H  16.0   8.0   \n",
       "2   3.0  20.0  0.0  15.0  3.0  2.0       Hannover  08/08/09   H   5.0  16.0   \n",
       "3  10.0  28.0  0.0   9.0  3.0  2.0  Bayern Munich  08/08/09   D   3.0  10.0   \n",
       "4   5.0  28.0  0.0  13.0  7.0  2.0     Leverkusen  08/08/09   D   3.0  22.0   \n",
       "\n",
       "    HR    HS   HST  HTAG  HTHG   HY    HomeTeam      league  \n",
       "0  0.0  13.0   7.0   0.0   0.0  0.0   Wolfsburg  bundesliga  \n",
       "1  0.0  24.0  11.0   0.0   0.0  0.0    Dortmund  bundesliga  \n",
       "2  0.0  10.0   4.0   0.0   0.0  3.0      Hertha  bundesliga  \n",
       "3  0.0   9.0   1.0   1.0   1.0  0.0  Hoffenheim  bundesliga  \n",
       "4  0.0   8.0   4.0   2.0   1.0  1.0       Mainz  bundesliga  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna(axis = 0, how ='any') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= df_cleaned.drop(\"FTR\",axis=1)\n",
    "X = X.drop(\"Date\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"AwayTeamEnc\"] = le.fit_transform(X[\"AwayTeam\"].astype(str))\n",
    "X[\"HomeTeamEnc\"] = le.fit_transform(X[\"HomeTeam\"].astype(str))\n",
    "X[\"leagueEnc\"] = le.fit_transform(X[\"league\"].astype(str))\n",
    "X= X.drop(\"AwayTeam\", axis=1)\n",
    "X=X.drop(\"HomeTeam\", axis=1)\n",
    "X= X.drop(\"league\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.fit_transform(df_cleaned.FTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12776, 17), (12776,), (12776, 3))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape , dummy_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def twolayer_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(34, input_dim=17, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "estimator = KerasClassifier(build_fn=twolayer_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/srimugunthan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/srimugunthan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 65.15% (0.89%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65343979, 0.63982157, 0.66134337])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasClassifier at 0x7f74661f6ac8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12776/12776 [==============================] - 2s 191us/step - loss: 3.0091 - acc: 0.5475\n",
      "Epoch 2/150\n",
      "12776/12776 [==============================] - 2s 160us/step - loss: 0.8747 - acc: 0.6106\n",
      "Epoch 3/150\n",
      "12776/12776 [==============================] - 3s 212us/step - loss: 0.8459 - acc: 0.6223\n",
      "Epoch 4/150\n",
      "12776/12776 [==============================] - 3s 219us/step - loss: 0.8449 - acc: 0.6188\n",
      "Epoch 5/150\n",
      "12776/12776 [==============================] - 2s 140us/step - loss: 0.8363 - acc: 0.6296\n",
      "Epoch 6/150\n",
      "12776/12776 [==============================] - 2s 179us/step - loss: 0.8306 - acc: 0.6285\n",
      "Epoch 7/150\n",
      "12776/12776 [==============================] - 3s 196us/step - loss: 0.8213 - acc: 0.6292\n",
      "Epoch 8/150\n",
      "12776/12776 [==============================] - 3s 208us/step - loss: 0.8200 - acc: 0.6270\n",
      "Epoch 9/150\n",
      "12776/12776 [==============================] - 3s 234us/step - loss: 0.8250 - acc: 0.6256\n",
      "Epoch 10/150\n",
      "12776/12776 [==============================] - 4s 325us/step - loss: 0.8215 - acc: 0.6266\n",
      "Epoch 11/150\n",
      "12776/12776 [==============================] - 3s 218us/step - loss: 0.8192 - acc: 0.6281\n",
      "Epoch 12/150\n",
      "12776/12776 [==============================] - 3s 227us/step - loss: 0.8107 - acc: 0.6311\n",
      "Epoch 13/150\n",
      "12776/12776 [==============================] - 3s 197us/step - loss: 0.8114 - acc: 0.6308\n",
      "Epoch 14/150\n",
      "12776/12776 [==============================] - 3s 211us/step - loss: 0.7989 - acc: 0.6370\n",
      "Epoch 15/150\n",
      "12776/12776 [==============================] - 3s 250us/step - loss: 0.8057 - acc: 0.6306\n",
      "Epoch 16/150\n",
      "12776/12776 [==============================] - 3s 222us/step - loss: 0.7994 - acc: 0.6395\n",
      "Epoch 17/150\n",
      "12776/12776 [==============================] - 2s 154us/step - loss: 0.8064 - acc: 0.6304\n",
      "Epoch 18/150\n",
      "12776/12776 [==============================] - 2s 167us/step - loss: 0.7998 - acc: 0.6376\n",
      "Epoch 19/150\n",
      "12776/12776 [==============================] - 2s 147us/step - loss: 0.7945 - acc: 0.6363\n",
      "Epoch 20/150\n",
      "12776/12776 [==============================] - 2s 161us/step - loss: 0.7912 - acc: 0.6367\n",
      "Epoch 21/150\n",
      "12776/12776 [==============================] - 2s 139us/step - loss: 0.7951 - acc: 0.6322\n",
      "Epoch 22/150\n",
      "12776/12776 [==============================] - 2s 167us/step - loss: 0.7944 - acc: 0.6345\n",
      "Epoch 23/150\n",
      "12776/12776 [==============================] - 2s 157us/step - loss: 0.7832 - acc: 0.6450\n",
      "Epoch 24/150\n",
      "12776/12776 [==============================] - 2s 130us/step - loss: 0.7886 - acc: 0.6399\n",
      "Epoch 25/150\n",
      "12776/12776 [==============================] - 2s 148us/step - loss: 0.7818 - acc: 0.6378\n",
      "Epoch 26/150\n",
      "12776/12776 [==============================] - 3s 269us/step - loss: 0.7752 - acc: 0.6418\n",
      "Epoch 27/150\n",
      "12776/12776 [==============================] - 3s 250us/step - loss: 0.7834 - acc: 0.6399\n",
      "Epoch 28/150\n",
      "12776/12776 [==============================] - 2s 183us/step - loss: 0.7776 - acc: 0.6439\n",
      "Epoch 29/150\n",
      "12776/12776 [==============================] - 2s 195us/step - loss: 0.7795 - acc: 0.6415\n",
      "Epoch 30/150\n",
      "12776/12776 [==============================] - 2s 179us/step - loss: 0.7740 - acc: 0.6419\n",
      "Epoch 31/150\n",
      "12776/12776 [==============================] - 3s 198us/step - loss: 0.7747 - acc: 0.6452\n",
      "Epoch 32/150\n",
      "12776/12776 [==============================] - 2s 175us/step - loss: 0.7692 - acc: 0.6466\n",
      "Epoch 33/150\n",
      "12776/12776 [==============================] - 2s 191us/step - loss: 0.7712 - acc: 0.6480\n",
      "Epoch 34/150\n",
      "12776/12776 [==============================] - 2s 169us/step - loss: 0.7720 - acc: 0.6408\n",
      "Epoch 35/150\n",
      "12776/12776 [==============================] - 3s 200us/step - loss: 0.7639 - acc: 0.6461\n",
      "Epoch 36/150\n",
      "12776/12776 [==============================] - 2s 175us/step - loss: 0.7630 - acc: 0.6469\n",
      "Epoch 37/150\n",
      "12776/12776 [==============================] - 2s 182us/step - loss: 0.7664 - acc: 0.6463\n",
      "Epoch 38/150\n",
      "12776/12776 [==============================] - 2s 188us/step - loss: 0.7614 - acc: 0.6467\n",
      "Epoch 39/150\n",
      "12776/12776 [==============================] - 3s 232us/step - loss: 0.7603 - acc: 0.6473\n",
      "Epoch 40/150\n",
      "12776/12776 [==============================] - 2s 127us/step - loss: 0.7582 - acc: 0.6528\n",
      "Epoch 41/150\n",
      "12776/12776 [==============================] - 2s 122us/step - loss: 0.7558 - acc: 0.6491\n",
      "Epoch 42/150\n",
      "12776/12776 [==============================] - 2s 155us/step - loss: 0.7563 - acc: 0.6512\n",
      "Epoch 43/150\n",
      "12776/12776 [==============================] - 2s 156us/step - loss: 0.7552 - acc: 0.6486\n",
      "Epoch 44/150\n",
      "12776/12776 [==============================] - 2s 153us/step - loss: 0.7517 - acc: 0.6504\n",
      "Epoch 45/150\n",
      "12776/12776 [==============================] - 2s 136us/step - loss: 0.7525 - acc: 0.6510\n",
      "Epoch 46/150\n",
      "12776/12776 [==============================] - 2s 122us/step - loss: 0.7509 - acc: 0.6535\n",
      "Epoch 47/150\n",
      "12776/12776 [==============================] - 2s 121us/step - loss: 0.7525 - acc: 0.6522\n",
      "Epoch 48/150\n",
      "12776/12776 [==============================] - 2s 141us/step - loss: 0.7485 - acc: 0.6511\n",
      "Epoch 49/150\n",
      "12776/12776 [==============================] - 2s 146us/step - loss: 0.7471 - acc: 0.6585\n",
      "Epoch 50/150\n",
      "12776/12776 [==============================] - 2s 193us/step - loss: 0.7488 - acc: 0.6547\n",
      "Epoch 51/150\n",
      "12776/12776 [==============================] - 4s 304us/step - loss: 0.7451 - acc: 0.6588\n",
      "Epoch 52/150\n",
      "12776/12776 [==============================] - 3s 256us/step - loss: 0.7470 - acc: 0.6543\n",
      "Epoch 53/150\n",
      "12776/12776 [==============================] - 3s 211us/step - loss: 0.7458 - acc: 0.6565\n",
      "Epoch 54/150\n",
      "12776/12776 [==============================] - 2s 141us/step - loss: 0.7418 - acc: 0.6576\n",
      "Epoch 55/150\n",
      "12776/12776 [==============================] - 2s 149us/step - loss: 0.7423 - acc: 0.6580\n",
      "Epoch 56/150\n",
      "12776/12776 [==============================] - 2s 178us/step - loss: 0.7426 - acc: 0.6587\n",
      "Epoch 57/150\n",
      "12776/12776 [==============================] - 3s 211us/step - loss: 0.7427 - acc: 0.6583\n",
      "Epoch 58/150\n",
      "12776/12776 [==============================] - 3s 209us/step - loss: 0.7414 - acc: 0.6601\n",
      "Epoch 59/150\n",
      "12776/12776 [==============================] - 2s 191us/step - loss: 0.7391 - acc: 0.6582\n",
      "Epoch 60/150\n",
      "12776/12776 [==============================] - 3s 214us/step - loss: 0.7393 - acc: 0.6593\n",
      "Epoch 61/150\n",
      "12776/12776 [==============================] - 2s 170us/step - loss: 0.7405 - acc: 0.6565\n",
      "Epoch 62/150\n",
      "12776/12776 [==============================] - 3s 197us/step - loss: 0.7379 - acc: 0.6608\n",
      "Epoch 63/150\n",
      "12776/12776 [==============================] - 3s 218us/step - loss: 0.7394 - acc: 0.6603\n",
      "Epoch 64/150\n",
      "12776/12776 [==============================] - 3s 219us/step - loss: 0.7378 - acc: 0.6580\n",
      "Epoch 65/150\n",
      "12776/12776 [==============================] - 2s 185us/step - loss: 0.7366 - acc: 0.6626\n",
      "Epoch 66/150\n",
      "12776/12776 [==============================] - 3s 199us/step - loss: 0.7371 - acc: 0.6572\n",
      "Epoch 67/150\n",
      "12776/12776 [==============================] - 2s 168us/step - loss: 0.7366 - acc: 0.6594\n",
      "Epoch 68/150\n",
      "12776/12776 [==============================] - 2s 188us/step - loss: 0.7342 - acc: 0.6620\n",
      "Epoch 69/150\n",
      "12776/12776 [==============================] - 2s 169us/step - loss: 0.7341 - acc: 0.6586\n",
      "Epoch 70/150\n",
      "12776/12776 [==============================] - 3s 223us/step - loss: 0.7348 - acc: 0.6590\n",
      "Epoch 71/150\n",
      "12776/12776 [==============================] - 2s 171us/step - loss: 0.7344 - acc: 0.6606\n",
      "Epoch 72/150\n",
      "12776/12776 [==============================] - 2s 189us/step - loss: 0.7349 - acc: 0.6589\n",
      "Epoch 73/150\n",
      "12776/12776 [==============================] - 2s 171us/step - loss: 0.7344 - acc: 0.6631\n",
      "Epoch 74/150\n",
      "12776/12776 [==============================] - 2s 195us/step - loss: 0.7320 - acc: 0.6620\n",
      "Epoch 75/150\n",
      "12776/12776 [==============================] - 3s 201us/step - loss: 0.7326 - acc: 0.6616\n",
      "Epoch 76/150\n",
      "12776/12776 [==============================] - 2s 195us/step - loss: 0.7323 - acc: 0.6588\n",
      "Epoch 77/150\n",
      "12776/12776 [==============================] - 2s 173us/step - loss: 0.7327 - acc: 0.6627\n",
      "Epoch 78/150\n",
      "12776/12776 [==============================] - 2s 195us/step - loss: 0.7330 - acc: 0.6610\n",
      "Epoch 79/150\n",
      "12776/12776 [==============================] - 2s 175us/step - loss: 0.7297 - acc: 0.6616\n",
      "Epoch 80/150\n",
      "12776/12776 [==============================] - 2s 179us/step - loss: 0.7312 - acc: 0.6612\n",
      "Epoch 81/150\n",
      "12776/12776 [==============================] - 2s 184us/step - loss: 0.7302 - acc: 0.6611\n",
      "Epoch 82/150\n",
      "12776/12776 [==============================] - 2s 175us/step - loss: 0.7307 - acc: 0.6594\n",
      "Epoch 83/150\n",
      "12776/12776 [==============================] - 2s 194us/step - loss: 0.7306 - acc: 0.6619\n",
      "Epoch 84/150\n",
      "12776/12776 [==============================] - 2s 177us/step - loss: 0.7307 - acc: 0.6632\n",
      "Epoch 85/150\n",
      "12776/12776 [==============================] - 4s 298us/step - loss: 0.7301 - acc: 0.6616\n",
      "Epoch 86/150\n",
      "12776/12776 [==============================] - 5s 380us/step - loss: 0.7298 - acc: 0.6609\n",
      "Epoch 87/150\n",
      "12776/12776 [==============================] - 4s 351us/step - loss: 0.7307 - acc: 0.6655\n",
      "Epoch 88/150\n",
      "12776/12776 [==============================] - 4s 341us/step - loss: 0.7300 - acc: 0.6609\n",
      "Epoch 89/150\n",
      "12776/12776 [==============================] - 2s 186us/step - loss: 0.7287 - acc: 0.6652\n",
      "Epoch 90/150\n",
      "12776/12776 [==============================] - 3s 210us/step - loss: 0.7284 - acc: 0.6651\n",
      "Epoch 91/150\n",
      "12776/12776 [==============================] - 2s 177us/step - loss: 0.7284 - acc: 0.6638\n",
      "Epoch 92/150\n",
      "12776/12776 [==============================] - 3s 250us/step - loss: 0.7282 - acc: 0.6623\n",
      "Epoch 93/150\n",
      "12776/12776 [==============================] - 4s 315us/step - loss: 0.7295 - acc: 0.6634\n",
      "Epoch 94/150\n",
      "12776/12776 [==============================] - 4s 325us/step - loss: 0.7285 - acc: 0.6611\n",
      "Epoch 95/150\n",
      "12776/12776 [==============================] - 2s 190us/step - loss: 0.7274 - acc: 0.6661\n",
      "Epoch 96/150\n",
      "12776/12776 [==============================] - 4s 300us/step - loss: 0.7285 - acc: 0.6638\n",
      "Epoch 97/150\n",
      "12776/12776 [==============================] - 5s 364us/step - loss: 0.7280 - acc: 0.6679\n",
      "Epoch 98/150\n",
      "12776/12776 [==============================] - 5s 359us/step - loss: 0.7259 - acc: 0.6635\n",
      "Epoch 99/150\n",
      "12776/12776 [==============================] - 2s 196us/step - loss: 0.7257 - acc: 0.6656\n",
      "Epoch 100/150\n",
      "12776/12776 [==============================] - 3s 197us/step - loss: 0.7267 - acc: 0.6642\n",
      "Epoch 101/150\n",
      "12776/12776 [==============================] - 2s 193us/step - loss: 0.7269 - acc: 0.6641\n",
      "Epoch 102/150\n",
      "12776/12776 [==============================] - 3s 247us/step - loss: 0.7269 - acc: 0.6640\n",
      "Epoch 103/150\n",
      "12776/12776 [==============================] - 2s 171us/step - loss: 0.7253 - acc: 0.6669\n",
      "Epoch 104/150\n",
      "12776/12776 [==============================] - 4s 322us/step - loss: 0.7261 - acc: 0.6634\n",
      "Epoch 105/150\n",
      "12776/12776 [==============================] - 3s 217us/step - loss: 0.7251 - acc: 0.6662\n",
      "Epoch 106/150\n",
      "12776/12776 [==============================] - 3s 222us/step - loss: 0.7254 - acc: 0.6630\n",
      "Epoch 107/150\n",
      "12776/12776 [==============================] - 5s 371us/step - loss: 0.7242 - acc: 0.6647\n",
      "Epoch 108/150\n",
      "12776/12776 [==============================] - 3s 236us/step - loss: 0.7259 - acc: 0.6648\n",
      "Epoch 109/150\n",
      "12776/12776 [==============================] - 2s 177us/step - loss: 0.7244 - acc: 0.6641\n",
      "Epoch 110/150\n",
      "12776/12776 [==============================] - 3s 200us/step - loss: 0.7252 - acc: 0.6636\n",
      "Epoch 111/150\n",
      "12776/12776 [==============================] - 2s 185us/step - loss: 0.7246 - acc: 0.6688\n",
      "Epoch 112/150\n",
      "12776/12776 [==============================] - 2s 181us/step - loss: 0.7261 - acc: 0.6666\n",
      "Epoch 113/150\n",
      "12776/12776 [==============================] - 2s 193us/step - loss: 0.7247 - acc: 0.6650\n",
      "Epoch 114/150\n",
      "12776/12776 [==============================] - 2s 179us/step - loss: 0.7234 - acc: 0.6652\n",
      "Epoch 115/150\n",
      "12776/12776 [==============================] - 2s 192us/step - loss: 0.7246 - acc: 0.6670\n",
      "Epoch 116/150\n",
      "12776/12776 [==============================] - 2s 178us/step - loss: 0.7244 - acc: 0.6655\n",
      "Epoch 117/150\n",
      "12776/12776 [==============================] - 3s 205us/step - loss: 0.7250 - acc: 0.6653\n",
      "Epoch 118/150\n",
      "12776/12776 [==============================] - 2s 185us/step - loss: 0.7237 - acc: 0.6655\n",
      "Epoch 119/150\n",
      "12776/12776 [==============================] - 3s 197us/step - loss: 0.7244 - acc: 0.6679\n",
      "Epoch 120/150\n",
      "12776/12776 [==============================] - 2s 180us/step - loss: 0.7236 - acc: 0.6619\n",
      "Epoch 121/150\n",
      "12776/12776 [==============================] - 3s 202us/step - loss: 0.7224 - acc: 0.6662\n",
      "Epoch 122/150\n",
      "12776/12776 [==============================] - 2s 183us/step - loss: 0.7231 - acc: 0.6677\n",
      "Epoch 123/150\n",
      "12776/12776 [==============================] - 3s 203us/step - loss: 0.7234 - acc: 0.6651\n",
      "Epoch 124/150\n",
      "12776/12776 [==============================] - 2s 177us/step - loss: 0.7233 - acc: 0.6656\n",
      "Epoch 125/150\n",
      "12776/12776 [==============================] - 3s 203us/step - loss: 0.7224 - acc: 0.6640\n",
      "Epoch 126/150\n",
      "12776/12776 [==============================] - 3s 221us/step - loss: 0.7215 - acc: 0.6659\n",
      "Epoch 127/150\n",
      "12776/12776 [==============================] - 3s 217us/step - loss: 0.7236 - acc: 0.6665\n",
      "Epoch 128/150\n",
      "12776/12776 [==============================] - 2s 195us/step - loss: 0.7254 - acc: 0.6635\n",
      "Epoch 129/150\n",
      "12776/12776 [==============================] - 2s 192us/step - loss: 0.7210 - acc: 0.6666\n",
      "Epoch 130/150\n",
      "12776/12776 [==============================] - 2s 179us/step - loss: 0.7246 - acc: 0.6626\n",
      "Epoch 131/150\n",
      "12776/12776 [==============================] - 3s 199us/step - loss: 0.7220 - acc: 0.6661\n",
      "Epoch 132/150\n",
      "12776/12776 [==============================] - 3s 231us/step - loss: 0.7230 - acc: 0.6666\n",
      "Epoch 133/150\n",
      "12776/12776 [==============================] - 3s 212us/step - loss: 0.7214 - acc: 0.6659\n",
      "Epoch 134/150\n",
      "12776/12776 [==============================] - 2s 183us/step - loss: 0.7216 - acc: 0.6643\n",
      "Epoch 135/150\n",
      "12776/12776 [==============================] - 3s 268us/step - loss: 0.7227 - acc: 0.6669\n",
      "Epoch 136/150\n",
      "12776/12776 [==============================] - 3s 229us/step - loss: 0.7210 - acc: 0.6680\n",
      "Epoch 137/150\n",
      "12776/12776 [==============================] - 2s 168us/step - loss: 0.7221 - acc: 0.6646\n",
      "Epoch 138/150\n",
      "12776/12776 [==============================] - 2s 190us/step - loss: 0.7203 - acc: 0.6666\n",
      "Epoch 139/150\n",
      "12776/12776 [==============================] - 3s 235us/step - loss: 0.7225 - acc: 0.6636\n",
      "Epoch 140/150\n",
      "12776/12776 [==============================] - 3s 196us/step - loss: 0.7213 - acc: 0.6656\n",
      "Epoch 141/150\n",
      "12776/12776 [==============================] - 2s 178us/step - loss: 0.7225 - acc: 0.6692\n",
      "Epoch 142/150\n",
      "12776/12776 [==============================] - 2s 185us/step - loss: 0.7210 - acc: 0.6648\n",
      "Epoch 143/150\n",
      "12776/12776 [==============================] - 2s 176us/step - loss: 0.7212 - acc: 0.6670\n",
      "Epoch 144/150\n",
      "12776/12776 [==============================] - 3s 230us/step - loss: 0.7217 - acc: 0.6657\n",
      "Epoch 145/150\n",
      "12776/12776 [==============================] - 3s 214us/step - loss: 0.7211 - acc: 0.6689\n",
      "Epoch 146/150\n",
      "12776/12776 [==============================] - 3s 203us/step - loss: 0.7190 - acc: 0.6696\n",
      "Epoch 147/150\n",
      "12776/12776 [==============================] - 2s 185us/step - loss: 0.7209 - acc: 0.6655\n",
      "Epoch 148/150\n",
      "12776/12776 [==============================] - 3s 199us/step - loss: 0.7215 - acc: 0.6706\n",
      "Epoch 149/150\n",
      "12776/12776 [==============================] - 2s 190us/step - loss: 0.7196 - acc: 0.6691\n",
      "Epoch 150/150\n",
      "12776/12776 [==============================] - 3s 203us/step - loss: 0.7211 - acc: 0.6678\n"
     ]
    }
   ],
   "source": [
    "model = twolayer_model()\n",
    "trainedmodel = model.fit(X, dummy_y, epochs=150, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12776/12776 [==============================] - 1s 51us/step\n",
      "Accuracy: 66.70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_, accuracy = model.evaluate(X, dummy_y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = trainedmodel.predict(X)\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "predictions = model.predict_classes(X)\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
